# Micro-Wildfire Prediction with AI

#Author-  Rhea Ghosal
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report, roc_curve, auc

 
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, Flatten, LSTM
 
from aif360.datasets import BinaryLabelDataset
from aif360.metrics import BinaryLabelDatasetMetric
from aif360.algorithms.preprocessing import Reweighing

 
np.random.seed(42)
tf.random.set_seed(42)

# Step 1: Data Collection
def load_wildfire_data():
    """
    Simulated function to load wildfire data.
    Replace with actual dataset loading from NASA MODIS, NOAA, or other sources.
    """
    n_samples = 10000  # Simulated dataset size
    data = pd.DataFrame({
        'temperature': np.random.normal(30, 5, n_samples),
        'humidity': np.random.normal(50, 10, n_samples),
        'wind_speed': np.random.normal(10, 3, n_samples),
        'smoke_level': np.random.normal(5, 2, n_samples),
        'fire_risk': np.random.choice([0, 1], size=n_samples, p=[0.7, 0.3])  # Imbalanced dataset
    })
    return data

# Load dataset
wildfire_data = load_wildfire_data()

# Step 2: Data Preprocessing
def preprocess_data(data):
    """
    Preprocesses the wildfire dataset by handling missing values, normalizing features, and splitting the data.
    """
    # Handle missing values (if any)
    data.dropna(inplace=True)

    # Feature scaling
    scaler = StandardScaler()
    X = scaler.fit_transform(data.drop(columns=['fire_risk']))
    y = data['fire_risk']

    # Train-test split
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    return X_train, X_test, y_train, y_test

# Preprocess dataset
X_train, X_test, y_train, y_test = preprocess_data(wildfire_data)

# Step 3: Apply AI Ethics - Addressing Data Bias
def apply_fairness_checks(X_train, y_train):
    """
    Applies AI fairness checks using the AIF360 toolkit to detect dataset imbalances.
    """
    dataset = pd.DataFrame(X_train, columns=['temperature', 'humidity', 'wind_speed', 'smoke_level'])
    dataset['fire_risk'] = y_train.values

    # Convert to AIF360 BinaryLabelDataset
    binary_dataset = BinaryLabelDataset(df=dataset, label_names=['fire_risk'], protected_attribute_names=['humidity'])

    # Compute bias metric
    metric = BinaryLabelDatasetMetric(binary_dataset, privileged_groups=[{'humidity': 1}], unprivileged_groups=[{'humidity': 0}])
    print(f"Disparate Impact Ratio: {metric.disparate_impact()}")

    # Apply reweighting to correct dataset bias
    reweighing = Reweighing(unprivileged_groups=[{'humidity': 0}], privileged_groups=[{'humidity': 1}])
    dataset_transformed = reweighing.fit_transform(binary_dataset)
    return dataset_transformed

# Apply fairness corrections
X_train_transformed = apply_fairness_checks(X_train, y_train)

# Step 4: Model Training and Evaluation
def train_models(X_train, X_test, y_train, y_test):
    """
    Trains multiple models (Logistic Regression, Random Forest, XGBoost, CNN, LSTM) and evaluates performance.
    """
    models = {
        "Logistic Regression": LogisticRegression(),
        "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42),
        "XGBoost": XGBClassifier(use_label_encoder=False, eval_metric='logloss')
    }

    results = {}
    roc_curves = {}

    for name, model in models.items():
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        acc = accuracy_score(y_test, y_pred)
        results[name] = acc

        # Compute ROC curve
        fpr, tpr, _ = roc_curve(y_test, model.predict_proba(X_test)[:, 1])
        roc_curves[name] = (fpr, tpr, auc(fpr, tpr))

    return results, roc_curves

# Train traditional models
results, roc_curves = train_models(X_train, X_test, y_train, y_test)

# Step 5: CNN Model for Wildfire Image Classification (Simulated)
def train_cnn_model():
    """
    Trains a simple CNN model (placeholder for satellite image classification).
    """
    model = Sequential([
        Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(64, 64, 3)),
        Flatten(),
        Dense(64, activation='relu'),
        Dense(1, activation='sigmoid')
    ])
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    return model

# Train LSTM Model for Time-Series Prediction
def train_lstm_model(X_train, y_train):
    """
    Trains an LSTM model on sequential wildfire risk prediction.
    """
    model = Sequential([
        LSTM(50, return_sequences=True, input_shape=(10, 4)),
        LSTM(50),
        Dense(1, activation='sigmoid')
    ])
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    return model

# Step 6: Model Performance Visualization
def plot_results(results, roc_curves):
    """
    Plots model accuracy comparison and ROC curves.
    """
    # Accuracy Comparison
    plt.figure(figsize=(8, 5))
    plt.bar(results.keys(), results.values(), color=['blue', 'green', 'red'])
    plt.xlabel("Machine Learning Models")
    plt.ylabel("Accuracy")
    plt.title("Model Accuracy Comparison")
    plt.ylim(0, 1)
    plt.savefig("/mnt/data/model_accuracy_comparison.png")
    plt.close()

    # ROC Curve Comparison
    plt.figure(figsize=(8, 6))
    for name, (fpr, tpr, roc_auc) in roc_curves.items():
        plt.plot(fpr, tpr, label=f"{name} (AUC = {roc_auc:.2f})")

    plt.plot([0, 1], [0, 1], linestyle="--", color="gray")
    plt.xlabel("False Positive Rate")
    plt.ylabel("True Positive Rate")
    plt.title("ROC Curve Comparison")
    plt.legend()
    plt.savefig("/mnt/data/roc_curve_comparison.png")
    plt.close()

# Generate and save plots
plot_results(results, roc_curves)

# Paths to saved plots
["/mnt/data/model_accuracy_comparison.png", "/mnt/data/roc_curve_comparison.png"]
